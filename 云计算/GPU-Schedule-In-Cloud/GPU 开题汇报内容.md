<!-- TOC -->

- [1. 概述](#1-概述)
- [2. 研究背景](#2-研究背景)
    - [2.1 应用场景](#21-应用场景)
        - [2.1.1 云游戏](#211-云游戏)
            - [2.1.1.1 成本](#2111-成本)
            - [2.1.1.2 Wine在容器中使用GPU](#2112-wine在容器中使用gpu)
        - [2.1.2 训练](#212-训练)
- [3. 研究内容](#3-研究内容)
    - [3.1 批量调度](#31-批量调度)
    - [3.2 拓扑结构](#32-拓扑结构)
    - [3.3 弹性调度](#33-弹性调度)
- [4. 实现路线](#4-实现路线)
    - [4.1 实现的侧重点](#41-实现的侧重点)
    - [4.2 实现详细计划](#42-实现详细计划)
- [参考文献](#参考文献)

<!-- /TOC -->
# 1. 概述
“云原生”是近年来最火的词之一，在云上有非常多可以做的事情。GPU是一种非常特殊资源，昂贵、功耗高、共享能力差、拓扑敏感（下面描述到）。但是，目前云平台上GPU利用率并不高，如果能提高平台上GPU利用率将是一件非常有实际意义事情。

本人准备做的是在容器云上将GPU任务调度到合适节点上，考虑的因素有批量调度、拓扑敏感、弹性调度。
* 批量调度是对一组多GPU任务，要么全调度，要目一个也不调度。
* 拓扑敏感指的是GPU之间的拓扑结构对任务性能影响很大，劲量将任务调度到相邻节点上。弹性调度是“云原生”的基本功能，指的是任务能根据当前集群GPU负载情况动态申请GPU数量。其中，实现的重点是弹性调度，因为目前没有任何一款针对云平台上针对GPU通用任务的弹性调度，并且实现的技术路线比较清楚。

该调度器的应用场景主要是云上对GPU资源有需求场景，主要有云游戏（如Google今年年初发布的Stadia，腾讯即将发布的START），另外是深度学习领域（如云端学习、边缘计算）。

另外，该领域非常新并且有非常多领域可以做，比如2018年Kubernetes才在容器云中取得统治地位，阿里已经实现全面使用容器。但是kubernetes没有提供对GPU任务的专门支持，默认的GPU调度有非常多的问题。目前GitHub社区上容器云提供GPU调度提供专门支持的热门项目只有kube-batch,但是现在只有小版本，并且没有拓扑感知和弹性调度的功能。

总的来说，研究云上弹性调度的优势是占了先机的优势，社区项目一大半时间在PR（Pull Request）的争论中，并且目前还不支持现弹性调度功能。

# 2. 研究背景
## 2.1 应用场景
### 2.1.1 云游戏
随着视屏编解码技术发展和5G时代的到来，云游戏厂商纷纷推出自身的云游戏平台占据市场，比如Google今年发布的Stadia，国内Tencent也即将发布自己的START平台。如果云游戏平台成功落地，相信对游戏市场影响深远。

#### 2.1.1.1 成本
云游戏GPU成本一定非常高，如下图所示，是今年11月份腾讯开发者大会上腾讯音视频实验室提供的一份START成本构成图，图中显示是带宽成本第一占34%，GPU成本第二占27%。但是改图是腾讯做视屏编解码技术提出的，但是视屏编解码有很大一部分是专利费用，并且google已经开源了其vpx系列，未来的视屏编解码成本相信会降低。还有GPU功耗是单独算在“机架、电力部分”。
![](images/2019-11-20-10-19-19.png)

#### 2.1.1.2 Wine在容器中使用GPU
* 不需要额外配置Wine-Staging提供对GPU直接支持（https://wiki.winehq.org/Wine-Staging_CUDA）。
* 该项目实现Wine在容器中使用GPU资源。https://github.com/scottyhardy/docker-wine
* CrossOver 运行在docker中。https://github.com/john-shine/Docker-CodeWeavers_CrossOver-VNC

### 2.1.2 训练
随着云计算的发展，越来越多企业开始退出自己的深度学习训练平台，来降低深度学习门槛和成本，典型的如青云、paddlepaddle以及中科院的诸葛·深知。

* 商汤的数据

# 3. 研究内容
## 3.1 批量调度
kubernetes 主要是解决无状态微服务的，对多GPU有状态任务支持并不友善。kubernetes默认调度策略是，不管任务请求多少个GPU，先尽可能占用GPU，如果资源不满足就阻塞，并且不会主动释放资源。这样一定会出现大任务阻塞小任务、资源死锁等问题。比如任务A需要4个GPU、任务B需要2个GPU、集群中还剩2个GPU，理想状态是任务B被调度，任务A阻塞，但是实际是任务A先占用2个GPU，任务A和B均阻塞。

批量调度是指，当集群中GPU资源满足任务请求数量时，该任务才被分配资源。达到的效果就是要么请求资源全部被满足，要么一个也不满足。

该需求开源项目kube-batch基本可以满足，但是该项目关于饥饿的解决还在争论中。

## 3.2 拓扑结构
* GPU 可以说对拓扑链路非常敏感，通常的链路通道包括网络、CPU、PCI SWitch、Nvlink等。

如下图所示，不同的拓扑结构对通信的速率有着重要影响，抛最后两项nvidia推出的产品，传统的PCI SWitch通道速度也是QPI通道的2.4倍。任务调度到合理的节点有利于提高GPU任务性能。（参考chrome-extension://cdonnmffkdaoajfknoeeecmchibpmkmg/assets/pdf/web/viewer.html?file=http%3A%2F%2Fon-demand.gputechconf.com%2Fgtc%2F2018%2Fpresentation%2Fs8462-multi-gpu-training-with-nccl.pdf）
![](2019-11-20-11-29-03.png)

## 3.3 弹性调度
云有很多特点，最重要的有高性能、高可用、可扩展、弹性等。
实现GPU弹性调度是希望实现根据集群资源情况动态的为任务分配GPU资源。提供集群GPU资源利用率。

阿里在2019年9月在Google开发者大会上海站上发布了ElasticDL，目前第一个针对TensorFlow 2.0 训练任务实现弹性调度。（https://developer.aliyun.com/article/718209）。该项目局限性在于只支持TensorFlow 2.0，调度没考虑到GPU支持、GPU弹性调度使用方式嵌入在代码中。
# 4. 实现路线
## 4.1 实现的侧重点
* 批量调度基于kube-batch实现，有现成的策略和方案。
* 根据GPU拓扑结构，将任务调度到合适的节点上。但是GPU拓扑结构非常复杂，根据拓扑结构调度本身就是一个很有意思的方向。目前没准备根据拓扑结构设计复杂的算法，只是会将多GPU任务竟可能调度在同一节点上。
* 弹性调度是实现的重点，目的是根据集群GPU使用情况，动态为任务分配GPU资源。我们需要实现的主要有两部分，首先我们需要一个controller实现状态机，具体实现调度的扩容和缩容的状态转换，另外还需要一个调度器去执行具体的调度算法和策略。

## 4.2 实现详细计划

* 【完成】调研Wine对GPU资源支持
* 【完成】调研开源的controller实现状态机。准备使用开源tf-operator或者pytorch-operator,这两个controller结构类似选择任何一个即可。这两个controller主要利用在深度学习场景，但是其对GPU静态任务创建和维护有着相对完善的结构和机制。弹性调度的状态机实现和维护可以在其基础上实现和维护。
* 【完成】调研GPU调度器，目前开源社区唯一火热的开源项目是kube-batch，其实现了基础的批量调度功能。根据拓扑感知和弹性调度还需要修改该调度器的调度算法。
* 【完成】pytorch-operator 开源项目源码阅读完毕，并且画出了弹性调度的状态机
* 【进行中】kube-batch 源码阅读
* 【跟进中】基于pytorch-operator实现状态机
* 【跟进中】基于kube-batch实现具体的调度算法
* 【跟进中】控制器和调度器进行联调
* 【跟进中】在机器上跑结果，得出实验结论，参照点可以是开源的kube-batch中GPU利用率
* 【跟进中】完成毕业论文撰写

# 参考文献



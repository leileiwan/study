<!-- TOC -->

- [1. 背景](#1-背景)
- [2. cuda编程模型基础](#2-cuda编程模型基础)

<!-- /TOC -->
# 1. 背景
* 2006年，NVIDIA公司发布了CUDA，CUDA是建立在NVIDIA的GPUs上的一个通用并行计算平台和编程模型，基于CUDA编程可以利用GPUs的并行计算引擎来更加高效地解决比较复杂的计算难题。

* GPU并不是一个独立运行的计算平台，而需要与CPU协同工作，可以看成是CPU的协处理器，因此当我们在说GPU并行计算时，其实是指的基于CPU+GPU的异构计算架构

* 在异构计算架构中，GPU与CPU通过PCIe总线连接在一起来协同工作，CPU所在位置称为为主机端（host），而GPU所在位置称为设备端（device），如下图所示。
![](./images/2019-12-09-14-40-23.png)

* 可以看到GPU包括更多的运算核心，其特别适合数据并行的计算密集型任务，如大型矩阵运算，而CPU的运算核心较少，但是其可以实现复杂的逻辑运算，因此其适合控制密集型任务。另外，CPU上的线程是重量级的，上下文切换开销大，但是GPU由于存在很多核心，其线程是轻量级的。因此，基于CPU+GPU的异构计算平台可以优势互补，CPU负责处理逻辑复杂的串行程序，而GPU重点处理数据密集型的并行计算程序，从而发挥最大功效。
![](./images/2019-12-09-14-42-16.png)


# 2. cuda编程模型基础
* 在CUDA中，host和device是两个重要的概念，我们用host指代CPU及其内存，而用device指代GPU及其内存。
* CUDA程序中既包含host程序，又包含device程序，它们分别在CPU和GPU上运行。
* host与device之间可以进行通信，这样它们之间可以进行数据拷贝。
* 典型的CUDA程序的执行流程如下：
    * 分配host内存，并进行数据初始化；
    * 分配device内存，并从host将数据拷贝到device上；
    * 调用CUDA的核函数在device上完成指定的运算；
    * 将device上的运算结果拷贝到host上；
    * 释放device和host上分配的内存。
